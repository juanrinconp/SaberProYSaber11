{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba8a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl \n",
    "import six\n",
    "from IPython.display import FileLink\n",
    "\n",
    "\n",
    "pathout = './data/'\n",
    "if not os.path.exists(pathout):\n",
    "    os.mkdir(pathout) \n",
    "    pathgraphs = './graphs/'\n",
    "    if not os.path.exists(pathgraphs): \n",
    "        os.mkdir(pathgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c35087",
   "metadata": {},
   "outputs": [],
   "source": [
    "llave = pd.read_csv(pathout + 'Llave_Saber11_2006-1_2020-2_SaberPRO_2012-1_2020-2 (1).txt', delimiter = \",\" , encoding = 'utf8' , engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c961391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llave = llave.rename(columns = {'estu_consecutivo' : 'estu_consecutivo_PRO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d637c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2005_1 = pd.read_csv(pathout + 'SB11_20051.txt', delimiter = \"|\" , encoding = 'utf8' , engine='python')\n",
    "s2005_2 = pd.read_csv(pathout + 'SB11_20052.txt', delimiter = \"|\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2005_1['estu_consecutivo_11'] = s2005_1['ESTU_CONSECUTIVO']\n",
    "s2005_2['estu_consecutivo_11'] = s2005_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2005_1 = pd.merge(s2005_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2005_2 = pd.merge(s2005_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2005_1.columns = s2005_1.columns.str.lower()\n",
    "s2005_2.columns = s2005_2.columns.str.lower()\n",
    "\n",
    "s2005_1 = s2005_1.add_suffix('_S11')\n",
    "s2005_1['estu_consecutivo_11'] = s2005_1['estu_consecutivo_11_S11']\n",
    "s2005_1 = s2005_1.drop(columns=['estu_consecutivo_11_S11']) \n",
    "s2005_2 = s2005_2.add_suffix('_S11')\n",
    "s2005_2['estu_consecutivo_11'] = s2005_2['estu_consecutivo_11_S11']\n",
    "s2005_2 = s2005_2.drop(columns=['estu_consecutivo_11_S11']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b076e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2006_1 = pd.read_csv(pathout + 'SB11_20061.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2006_2 = pd.read_csv(pathout + 'SB11_20062.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2006_1['estu_consecutivo_11'] = s2006_1['estu_consecutivo']\n",
    "s2006_2['estu_consecutivo_11'] = s2006_2['estu_consecutivo']\n",
    "\n",
    "s2006_1 = pd.merge(s2006_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2006_2 = pd.merge(s2006_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2006_1.columns = s2006_1.columns.str.lower()\n",
    "s2006_2.columns = s2006_2.columns.str.lower()\n",
    "\n",
    "s2006_1 = s2006_1.add_suffix('_S11')\n",
    "s2006_1['estu_consecutivo_11'] = s2006_1['estu_consecutivo_11_S11']\n",
    "s2006_1 = s2006_1.drop(columns=['estu_consecutivo_11_S11']) \n",
    "s2006_2 = s2006_2.add_suffix('_S11')\n",
    "s2006_2['estu_consecutivo_11'] = s2006_2['estu_consecutivo_11_S11']\n",
    "s2006_2 = s2006_2.drop(columns=['estu_consecutivo_11_S11']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab6ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2007_1 = pd.read_csv(pathout + 'SB11_20071.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2007_2 = pd.read_csv(pathout + 'SB11_20072.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2007_1['estu_consecutivo_11'] = s2007_1['estu_consecutivo']\n",
    "s2007_2['estu_consecutivo_11'] = s2007_2['estu_consecutivo']\n",
    "\n",
    "s2007_1 = pd.merge(s2007_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2007_2 = pd.merge(s2007_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2007_1.columns = s2007_1.columns.str.lower()\n",
    "s2007_2.columns = s2007_2.columns.str.lower()\n",
    "\n",
    "s2007_1 = s2007_1.add_suffix('_S11')\n",
    "s2007_1['estu_consecutivo_11'] = s2007_1['estu_consecutivo_11_S11']\n",
    "s2007_1 = s2007_1.drop(columns=['estu_consecutivo_11_S11']) \n",
    "s2007_2 = s2007_2.add_suffix('_S11')\n",
    "s2007_2['estu_consecutivo_11'] = s2007_2['estu_consecutivo_11_S11']\n",
    "s2007_2 = s2007_2.drop(columns=['estu_consecutivo_11_S11']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4067c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2008_1 = pd.read_csv(pathout + 'SB11_20081.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2008_2 = pd.read_csv(pathout + 'SB11_20082.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2008_1['estu_consecutivo_11'] = s2008_1['estu_consecutivo']\n",
    "s2008_2['estu_consecutivo_11'] = s2008_2['estu_consecutivo']\n",
    "\n",
    "s2008_1 = pd.merge(s2008_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2008_2 = pd.merge(s2008_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2008_1.columns = s2008_1.columns.str.lower()\n",
    "s2008_2.columns = s2008_2.columns.str.lower()\n",
    "\n",
    "s2008_1 = s2008_1.add_suffix('_S11')\n",
    "s2008_1['estu_consecutivo_11'] = s2008_1['estu_consecutivo_11_S11']\n",
    "s2008_1 = s2008_1.drop(columns=['estu_consecutivo_11_S11']) \n",
    "s2008_2 = s2008_2.add_suffix('_S11')\n",
    "s2008_2['estu_consecutivo_11'] = s2008_2['estu_consecutivo_11_S11']\n",
    "s2008_2 = s2008_2.drop(columns=['estu_consecutivo_11_S11']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4122bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2009_1 = pd.read_csv(pathout + 'SB11_20091.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2009_2 = pd.read_csv(pathout + 'SB11_20092.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2009_1['estu_consecutivo_11'] = s2009_1['estu_consecutivo']\n",
    "s2009_2['estu_consecutivo_11'] = s2009_2['estu_consecutivo']\n",
    "\n",
    "s2009_1['estu_consecutivo_11'] = s2009_1['estu_consecutivo'].str.replace('SABER11200910', 'SB112009100').astype(str)\n",
    "s2009_1 = pd.merge(s2009_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2009_2 = pd.merge(s2009_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2009_1.columns = s2009_1.columns.str.lower()\n",
    "s2009_2.columns = s2009_2.columns.str.lower()\n",
    "\n",
    "s2009_1 = s2009_1.add_suffix('_S11')\n",
    "s2009_1['estu_consecutivo_11'] = s2009_1['estu_consecutivo_11_S11']\n",
    "s2009_1 = s2009_1.drop(columns=['estu_consecutivo_11_S11']) \n",
    "s2009_2 = s2009_2.add_suffix('_S11')\n",
    "s2009_2['estu_consecutivo_11'] = s2009_2['estu_consecutivo_11_S11']\n",
    "s2009_2 = s2009_2.drop(columns=['estu_consecutivo_11_S11']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c2bde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2010_1 = pd.read_csv(pathout + 'SB11_20101.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2010_2 = pd.read_csv(pathout + 'SB11_20102.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2010_1['estu_consecutivo_11'] = s2010_1['ESTU_CONSECUTIVO']\n",
    "s2010_2['estu_consecutivo_11'] = s2010_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2010_1 = pd.merge(s2010_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2010_2 = pd.merge(s2010_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2010_1.columns = s2010_1.columns.str.lower()\n",
    "s2010_2.columns = s2010_2.columns.str.lower()\n",
    "\n",
    "s2010_1 = s2010_1.add_suffix('_S11')\n",
    "s2010_1['estu_consecutivo_11'] = s2010_1['estu_consecutivo_11_S11']\n",
    "s2010_1 = s2010_1.drop(columns=['estu_consecutivo_11_S11']) \n",
    "s2010_2 = s2010_2.add_suffix('_S11')\n",
    "s2010_2['estu_consecutivo_11'] = s2010_2['estu_consecutivo_11_S11']\n",
    "s2010_2 = s2010_2.drop(columns=['estu_consecutivo_11_S11'])\n",
    "\n",
    "s2010_1 = s2010_1.reset_index(drop=True)\n",
    "\n",
    "\n",
    "s2010_2 = s2010_2.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2011_1 = pd.read_csv(pathout + 'SB11_20111.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2011_2 = pd.read_csv(pathout + 'SB11_20112.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2011_1['estu_consecutivo_11'] = s2011_1['ESTU_CONSECUTIVO']\n",
    "s2011_2['estu_consecutivo_11'] = s2011_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2011_1 = pd.merge(s2011_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2011_2 = pd.merge(s2011_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2011_1.columns = s2011_1.columns.str.lower()\n",
    "s2011_2.columns = s2011_2.columns.str.lower()\n",
    "\n",
    "s2011_1 = s2011_1.add_suffix('_S11')\n",
    "s2011_1['estu_consecutivo_11'] = s2011_1['estu_consecutivo_11_S11']\n",
    "s2011_1 = s2011_1.drop(columns=['estu_consecutivo_11_S11']) \n",
    "s2011_2 = s2011_2.add_suffix('_S11')\n",
    "s2011_2['estu_consecutivo_11'] = s2011_2['estu_consecutivo_11_S11']\n",
    "s2011_2 = s2011_2.drop(columns=['estu_consecutivo_11_S11']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba3f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2012_1 = pd.read_csv(pathout + 'SB11_20121.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2012_2 = pd.read_csv(pathout + 'SB11_20122.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2012_1['estu_consecutivo_11'] = s2012_1['ESTU_CONSECUTIVO']\n",
    "s2012_2['estu_consecutivo_11'] = s2012_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2012_1 = pd.merge(s2012_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2012_2 = pd.merge(s2012_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2012_1.columns = s2012_1.columns.str.lower()\n",
    "s2012_2.columns = s2012_2.columns.str.lower()\n",
    "\n",
    "s2012_1 = s2012_1.add_suffix('_S11')\n",
    "s2012_1['estu_consecutivo_11'] = s2012_1['estu_consecutivo_11_S11']\n",
    "s2012_1 = s2012_1.drop(columns=['estu_consecutivo_11_S11'])\n",
    "s2012_2 = s2012_2.add_suffix('_S11')\n",
    "s2012_2['estu_consecutivo_11'] = s2012_2['estu_consecutivo_11_S11']\n",
    "s2012_2 = s2012_2.drop(columns=['estu_consecutivo_11_S11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ba7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2013_1 = pd.read_csv(pathout + 'SB11_20131.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2013_2 = pd.read_csv(pathout + 'SB11_20132.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "\n",
    "s2013_1['estu_consecutivo_11'] = s2013_1['ESTU_CONSECUTIVO']\n",
    "s2013_2['estu_consecutivo_11'] = s2013_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2013_1 = pd.merge(s2013_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2013_2 = pd.merge(s2013_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2013_1.columns = s2013_1.columns.str.lower()\n",
    "s2013_2.columns = s2013_2.columns.str.lower()\n",
    "\n",
    "s2013_1 = s2013_1.add_suffix('_S11')\n",
    "s2013_1['estu_consecutivo_11'] = s2013_1['estu_consecutivo_11_S11']\n",
    "s2013_1 = s2013_1.drop(columns=['estu_consecutivo_11_S11'])\n",
    "s2013_2 = s2013_2.add_suffix('_S11')\n",
    "s2013_2['estu_consecutivo_11'] = s2013_2['estu_consecutivo_11_S11']\n",
    "s2013_2 = s2013_2.drop(columns=['estu_consecutivo_11_S11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd1a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2014_1 = pd.read_csv(pathout + 'SB11_20141.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2014_2 = pd.read_csv(pathout + 'SB11_20142.txt', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2014_1['estu_consecutivo_11'] = s2014_1['ESTU_CONSECUTIVO']\n",
    "s2014_2['estu_consecutivo_11'] = s2014_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2014_1 = pd.merge(s2014_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2014_2 = pd.merge(s2014_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2014_1.columns = s2014_1.columns.str.lower()\n",
    "s2014_2.columns = s2014_2.columns.str.lower()\n",
    "\n",
    "s2014_1 = s2014_1.add_suffix('_S11')\n",
    "s2014_1['estu_consecutivo_11'] = s2014_1['estu_consecutivo_11_S11']\n",
    "s2014_1 = s2014_1.drop(columns=['estu_consecutivo_11_S11'])\n",
    "s2014_2 = s2014_2.add_suffix('_S11')\n",
    "s2014_2['estu_consecutivo_11'] = s2014_2['estu_consecutivo_11_S11']\n",
    "s2014_2 = s2014_2.drop(columns=['estu_consecutivo_11_S11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ea7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2015_1 = pd.read_csv(pathout + 'SB11_20151.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2015_2 = pd.read_csv(pathout + 'SB11_20152.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2015_1['estu_consecutivo_11'] = s2015_1['ESTU_CONSECUTIVO']\n",
    "s2015_2['estu_consecutivo_11'] = s2015_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2015_1 = pd.merge(s2015_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2015_2 = pd.merge(s2015_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2015_1.columns = s2015_1.columns.str.lower()\n",
    "s2015_2.columns = s2015_2.columns.str.lower()\n",
    "\n",
    "s2015_1 = s2015_1.add_suffix('_S11')\n",
    "s2015_1['estu_consecutivo_11'] = s2015_1['estu_consecutivo_11_S11']\n",
    "s2015_1 = s2015_1.drop(columns=['estu_consecutivo_11_S11'])\n",
    "s2015_2 = s2015_2.add_suffix('_S11')\n",
    "s2015_2['estu_consecutivo_11'] = s2015_2['estu_consecutivo_11_S11']\n",
    "s2015_2 = s2015_2.drop(columns=['estu_consecutivo_11_S11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3027bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2016_1 = pd.read_csv(pathout + 'SB11_20161.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2016_2 = pd.read_csv(pathout + 'SB11_20162.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2016_1['estu_consecutivo_11'] = s2016_1['ESTU_CONSECUTIVO']\n",
    "s2016_2['estu_consecutivo_11'] = s2016_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2016_1 = pd.merge(s2016_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2016_2 = pd.merge(s2016_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2016_1.columns = s2016_1.columns.str.lower()\n",
    "s2016_2.columns = s2016_2.columns.str.lower()\n",
    "\n",
    "s2016_1 = s2016_1.add_suffix('_S11')\n",
    "s2016_1['estu_consecutivo_11'] = s2016_1['estu_consecutivo_11_S11']\n",
    "s2016_1 = s2016_1.drop(columns=['estu_consecutivo_11_S11'])\n",
    "s2016_2 = s2016_2.add_suffix('_S11')\n",
    "s2016_2['estu_consecutivo_11'] = s2016_2['estu_consecutivo_11_S11']\n",
    "s2016_2 = s2016_2.drop(columns=['estu_consecutivo_11_S11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71b67837",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2017_1 = pd.read_csv(pathout + 'SB11_20171.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2017_2 = pd.read_csv(pathout + 'SB11_20172.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2017_1['estu_consecutivo_11'] = s2017_1['ESTU_CONSECUTIVO']\n",
    "s2017_2['estu_consecutivo_11'] = s2017_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2017_1 = pd.merge(s2017_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2017_2 = pd.merge(s2017_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2017_1.columns = s2017_1.columns.str.lower()\n",
    "s2017_2.columns = s2017_2.columns.str.lower()\n",
    "\n",
    "s2017_1 = s2017_1.add_suffix('_S11')\n",
    "s2017_1['estu_consecutivo_11'] = s2017_1['estu_consecutivo_11_S11']\n",
    "s2017_1 = s2017_1.drop(columns=['estu_consecutivo_11_S11'])\n",
    "s2017_2 = s2017_2.add_suffix('_S11')\n",
    "s2017_2['estu_consecutivo_11'] = s2017_2['estu_consecutivo_11_S11']\n",
    "s2017_2 = s2017_2.drop(columns=['estu_consecutivo_11_S11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4be38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2018_1 = pd.read_csv(pathout + 'SB11_20181.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "s2018_2 = pd.read_csv(pathout + 'SB11_20182.TXT', delimiter = \"¬\" , encoding = 'utf8' , engine='python')\n",
    "\n",
    "s2018_1['estu_consecutivo_11'] = s2018_1['ESTU_CONSECUTIVO']\n",
    "s2018_2['estu_consecutivo_11'] = s2018_2['ESTU_CONSECUTIVO']\n",
    "\n",
    "s2018_1 = pd.merge(s2018_1 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "s2018_2 = pd.merge(s2018_2 , llave, on ='estu_consecutivo_11', how ='inner')\n",
    "\n",
    "s2018_1.columns = s2018_1.columns.str.lower()\n",
    "s2018_2.columns = s2018_2.columns.str.lower()\n",
    "\n",
    "s2018_1 = s2018_1.add_suffix('_S11')\n",
    "s2018_1['estu_consecutivo_11'] = s2018_1['estu_consecutivo_11_S11']\n",
    "s2018_1 = s2018_1.drop(columns=['estu_consecutivo_11_S11'])\n",
    "s2018_2 = s2018_2.add_suffix('_S11')\n",
    "s2018_2['estu_consecutivo_11'] = s2018_2['estu_consecutivo_11_S11']\n",
    "s2018_2 = s2018_2.drop(columns=['estu_consecutivo_11_S11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3adf166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = s2006_1.append(s2006_2)\n",
    "app = app.append(s2007_1)\n",
    "app = app.append(s2007_2)\n",
    "app = app.append(s2008_1)\n",
    "app = app.append(s2008_2)\n",
    "app = app.append(s2009_1)\n",
    "app = app.append(s2009_2)\n",
    "app = app.append(s2010_1)\n",
    "app = app.append(s2010_2)\n",
    "app = app.append(s2011_1)\n",
    "app = app.append(s2011_2)\n",
    "app = app.append(s2012_1)\n",
    "app = app.append(s2012_2)\n",
    "app = app.append(s2013_1)\n",
    "app = app.append(s2013_2)\n",
    "app = app.append(s2014_1)\n",
    "app = app.append(s2014_2)\n",
    "app = app.append(s2015_1)\n",
    "app = app.append(s2015_2)\n",
    "app = app.append(s2016_1)\n",
    "app = app.append(s2016_2)\n",
    "app = app.append(s2017_1)\n",
    "app = app.append(s2017_2)\n",
    "app = app.append(s2018_1)\n",
    "app = app.append(s2018_2)\n",
    "\n",
    "\n",
    "\n",
    "app['estu_consecutivo_PRO'] = app['estu_consecutivo_pro_S11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1c52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#app.to_csv('saber11.csv')\n",
    "#Para obtener una sola base con todos los estudiantes del saber11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40559386",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro2012_1 =  pd.read_stata(pathout + 'pro20121.dta')\n",
    "pro2012_1.columns = pro2012_1.columns.str.lower()\n",
    "pro2012_1['estu_consecutivo_PRO'] = pro2012_1['estu_consecutivo']\n",
    "pro2012_1 = pro2012_1.drop(columns=['estu_consecutivo'])\n",
    "pro2012_1 = pd.merge(pro2012_1 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "\n",
    "pro2012_2 =  pd.read_stata(pathout + 'pro20123.dta')\n",
    "pro2012_2.columns = pro2012_2.columns.str.lower()\n",
    "pro2012_2['estu_consecutivo_PRO'] = pro2012_2['estu_consecutivo']\n",
    "pro2012_2 = pro2012_2.drop(columns=['estu_consecutivo'])\n",
    "pro2012_2 = pd.merge(pro2012_2 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2013_1 =  pd.read_stata(pathout + 'pro20131.dta')\n",
    "pro2013_1.columns = pro2013_1.columns.str.lower()\n",
    "pro2013_1['estu_consecutivo_PRO'] = pro2013_1['estu_consecutivo']\n",
    "pro2013_1 = pro2013_1.drop(columns=['estu_consecutivo'])\n",
    "pro2013_1 = pd.merge(pro2013_1 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2013_2 =  pd.read_stata(pathout + 'pro20133.dta')\n",
    "pro2013_2.columns = pro2013_2.columns.str.lower()\n",
    "pro2013_2['estu_consecutivo_PRO'] = pro2013_2['estu_consecutivo']\n",
    "pro2013_2 = pro2013_2.drop(columns=['estu_consecutivo'])\n",
    "pro2013_2 = pd.merge(pro2013_2 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2014_1 =  pd.read_stata(pathout + 'pro20141.dta')\n",
    "pro2014_1.columns = pro2014_1.columns.str.lower()\n",
    "pro2014_1['estu_consecutivo_PRO'] = pro2014_1['estu_consecutivo']\n",
    "pro2014_1 = pro2014_1.drop(columns=['estu_consecutivo'])\n",
    "pro2014_1 = pd.merge(pro2014_1 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2014_2 =  pd.read_stata(pathout + 'pro20143.dta')\n",
    "pro2014_2.columns = pro2014_2.columns.str.lower()\n",
    "pro2014_2['estu_consecutivo_PRO'] = pro2014_2['estu_consecutivo']\n",
    "pro2014_2 = pro2014_2.drop(columns=['estu_consecutivo'])\n",
    "pro2014_2 = pd.merge(pro2014_2 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2015_1 =  pd.read_stata(pathout + 'pro20151.dta')\n",
    "pro2015_1.columns = pro2015_1.columns.str.lower()\n",
    "pro2015_1['estu_consecutivo_PRO'] = pro2015_1['estu_consecutivo']\n",
    "pro2015_1 = pro2015_1.drop(columns=['estu_consecutivo'])\n",
    "pro2015_1 = pd.merge(pro2015_1 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2015_2 =  pd.read_stata(pathout + 'pro20153.dta')\n",
    "pro2015_2.columns = pro2015_2.columns.str.lower()\n",
    "pro2015_2['estu_consecutivo_PRO'] = pro2015_2['estu_consecutivo']\n",
    "pro2015_2 = pro2015_2.drop(columns=['estu_consecutivo'])\n",
    "pro2015_2 = pd.merge(pro2015_2 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2016 = pd.read_stata(pathout + 'pro2016.dta')\n",
    "pro2016.columns = pro2016.columns.str.lower()\n",
    "pro2016['estu_consecutivo_PRO'] = pro2016['estu_consecutivo']\n",
    "pro2016 = pro2016.drop(columns=['estu_consecutivo'])\n",
    "pro2016 = pd.merge(pro2016 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2017 = pd.read_stata(pathout + 'pro2017.dta')\n",
    "pro2017.columns = pro2017.columns.str.lower()\n",
    "pro2017['estu_consecutivo_PRO'] = pro2017['estu_consecutivo']\n",
    "pro2017 = pro2017.drop(columns=['estu_consecutivo'])\n",
    "pro2017 = pd.merge(pro2017 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "pro2018 = pd.read_stata(pathout + 'pro2018.dta')\n",
    "pro2018.columns = pro2018.columns.str.lower()\n",
    "pro2018['estu_consecutivo_PRO'] = pro2018['estu_consecutivo']\n",
    "pro2018 = pro2018.drop(columns=['estu_consecutivo'])\n",
    "pro2018 = pd.merge(pro2018 , llave, on ='estu_consecutivo_PRO', how ='inner')\n",
    "\n",
    "\n",
    "pro2019 = pd.read_stata(pathout + 'pro2019.dta')\n",
    "pro2019.columns = pro2019.columns.str.lower()\n",
    "pro2019['estu_consecutivo_PRO'] = pro2019['estu_consecutivo']\n",
    "pro2019 = pro2019.drop(columns=['estu_consecutivo'])\n",
    "pro2019 = pd.merge(pro2019 , llave, on ='estu_consecutivo_PRO', how ='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc392bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = pro2012_2.append(pro2012_1)\n",
    "pro = pro.append(pro2013_1)\n",
    "pro = pro.append(pro2013_2)\n",
    "pro = pro.append(pro2014_1)\n",
    "pro = pro.append(pro2014_2)\n",
    "pro = pro.append(pro2015_1)\n",
    "pro = pro.append(pro2015_2)\n",
    "pro = pro.append(pro2016)\n",
    "pro = pro.append(pro2017)\n",
    "pro = pro.append(pro2018)\n",
    "pro = pro.append(pro2019)\n",
    "\n",
    "\n",
    "prollave = pro.merge(llave, on ='estu_consecutivo_PRO', how ='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7e4e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prollave.to_csv('SABERPRO.csv')\n",
    "#prollave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a19a1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROSB11= pd.merge(prollave, app, on ='estu_consecutivo_PRO', how ='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROSB11.to_csv('SPS11_Final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c47d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
